7. 深度学习中解决过拟合的问题的方法有哪些
8. esim的网络结构
9. transformer的网络结构，bert的网络结构，qanet的网络结构，bert的效果优化优化在什么地方
10. qanet的网络结构 
11. qanet embedding：字向量(卷积的字向量)  + 词向量（预训练的词向量）+ highway nets 网络
  12. embedding encoder: encoder blocker -> [(pos-encoding) + conv x # + self-attention + feed-forward]
  13. context-attetion layer：发现context query之间的关系，并在词的层面上，解析出query，context 中的关键词语
  14. model encoder layer: stack blocks
  15. output layer: 阅读理解 -> 在文章中的起始和结束位置
  16. qanet 的网络结构是怎样的？
  17. bert  的网络结构是怎样的？
