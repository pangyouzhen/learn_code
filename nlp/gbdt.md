# boost

boost 核心思想就是对残差拟合进行叠加

# 问题

1. gbdt和adaboost有什么区别
    1. 从名字上理解,GBDT GBDT的核心是对负(gradient)梯度进行拟合, adaboost是通过Adaptive 自适应(不断的发现分错的点,优化这些分错的点进行的)的方法进行的,
1. gbdt的使用梯度进行拟合,但是gbdt做分类的情况输出的离散值.这个怎么处理
    1. 使用类别预测的概率值和真实的概率值的差来拟合损失
1. gbdt的正则化有哪些方式都是怎么做的

# 联系

1. 